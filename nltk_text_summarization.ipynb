{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/aurora/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/aurora/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import bs4\n",
    "# bs4 = pip install beautifulsoup\n",
    "import urllib.request\n",
    "import re\n",
    "import nltk\n",
    "import heapq\n",
    "from fake_useragent import UserAgent\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding fake user agent to make it compatible with medium\n",
    "ua = UserAgent()\n",
    "url = 'https://thorchaincommunity.medium.com/thorchain-org-v0-2-mobile-ready-cb8af0c56369'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data\n",
    "user_agent = ua.google\n",
    "request = urllib.request.Request(url)\n",
    "request.add_header('User-Agent', user_agent)\n",
    "get_data = urllib.request.urlopen(request)\n",
    "post = get_data.read()\n",
    "\n",
    "parsed_post = bs4.BeautifulSoup(post, 'lxml')\n",
    "para = parsed_post.find_all('p')\n",
    "\n",
    "post_text = \"\"\n",
    "\n",
    "for p in para:\n",
    "    post_text += p.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing\n",
    "post_text = re.sub(r'\\[[0-9]*\\]',' ', post_text)\n",
    "post_text = re.sub(r'\\s+', ' ', post_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "form_post_text = re.sub('[^a-zA-Z]', ' ', post_text)\n",
    "form_post_text = re.sub(r'\\s+', ' ', form_post_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting txt to sentences\n",
    "sentence_list = nltk.sent_tokenize(post_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding frequencies\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "word_freq = {}\n",
    "for word in nltk.word_tokenize(form_post_text):\n",
    "    if word not in stopwords:\n",
    "        if word not in word_freq.keys():\n",
    "            word_freq[word] = 1\n",
    "        else:\n",
    "            word_freq[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_freq = max(word_freq.values())\n",
    "\n",
    "for word in word_freq.keys():\n",
    "    word_freq[word] = (word_freq[word]/max_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating sentence scores\n",
    "sentence_scores = {}\n",
    "for sent in sentence_list:\n",
    "    for word in nltk.word_tokenize(sent.lower()):\n",
    "        if word in word_freq.keys():\n",
    "            if len(sent.split(' ')) < 30:\n",
    "                if sent not in sentence_scores.keys():\n",
    "                    sentence_scores[sent] = word_freq[word]\n",
    "                else:\n",
    "                    sentence_scores[sent] += word_freq[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MehowBrains and TheHodlgraph (ex-buzzfeed producer) are knee-deep into architecting a new community-driven outbound marketing initiative, designed to create-original-content-and-repurpose community-created content into marketing landing pages/funnels for distribution into the masses.\n",
      "It was imperative that the website could prove its effectiveness as users consumed both internal and external content.\n",
      "The designer of the website outlines his investigation in this tweet:The developer immediately began to convert the website to relative units.\n",
      "TheHodlgraph and MehowBrains’s outbound marketing plan includes new methods to listen-for community-created content, to be fitted in the .org properties.\n",
      "On average users performed 2.6 external click events via 79K event clicks by 31K users.\n",
      "The THORChain.org website and marketing team thanks all supporters of its initiative.\n"
     ]
    }
   ],
   "source": [
    "#Summary with heapg\n",
    "#nlargest = top 5 sentences with highest scores\n",
    "summary_sentences = heapq.nlargest(6, sentence_scores, key=sentence_scores.get)\n",
    "\n",
    "summary = '\\n'.join(summary_sentences)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "Sending Summary through GPT2 Neural Network for better readability\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "print('--------------')\n",
    "print('Sending Summary through GPT2 Neural Network for better readability')\n",
    "print('--------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MehowBrains and TheHodlgraph (ex-buzzfeed producer) are knee-deep into architecting a new community-driven outbound marketing initiative, designed to create-original-content-and-repurpose community-created content into marketing landing pages/funnels for distribution into the masses.\n",
      "It was imperative that the website could prove its effectiveness as users consumed both internal and external content.\n",
      "The designer of the website outlines his investigation in this tweet:The developer immediately began to convert the website to relative units.\n",
      "TheHodlgraph and MehowBrains’s outbound marketing plan includes new methods to listen-for community-created content, to be fitted in the.org properties.\n",
      "On average users performed 2.6 external click events via 79K event clicks by 31K users.\n",
      "The THORChain.org website and marketing team thanks all supporters of its initiative.\n",
      "The Hodlgraph and MehowBrains’s outbound marketing plan includes new methods to listen-for community-created content, to be fitted in the.org properties.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Rewrite summary with GPT2\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "generated = tokenizer.encode(summary)\n",
    "context = torch.tensor([generated])\n",
    "past = None\n",
    "\n",
    "for i in range(40):\n",
    "# adjust range, 40 is enough for 6 sentences as used in heapq.nlargest\n",
    "    output = model(context, past_key_values=past)\n",
    "    past = output.past_key_values\n",
    "    token = torch.argmax(output.logits[..., -1, :])\n",
    "\n",
    "    generated += [token.tolist()]\n",
    "    context = token.unsqueeze(0)\n",
    "\n",
    "sequence = tokenizer.decode(generated)\n",
    "\n",
    "print(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
